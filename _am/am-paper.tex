\documentclass[sigchi, review]{acmart}
\usepackage{booktabs} % For formal tables

\usepackage[utf8x]{inputenc}
%\usepackage{flushend}
\PrerenderUnicode{aâîțșĂÎÂȚȘ}

% Copyright
%\setcopyright{none}
%\setcopyright{acmcopyright}
%\setcopyright{acmlicensed}
\setcopyright{rightsretained}
%\setcopyright{usgov}
%\setcopyright{usgovmixed}
%\setcopyright{cagov}
%\setcopyright{cagovmixed}


% DOI
\acmDOI{10.475/123_4}

% ISBN
\acmISBN{123-4567-24-567/08/06}

%Conference
\acmConference[AM'17]{AudioMostly conference}{August 2017}{London, UK} 
\acmYear{2017}
\copyrightyear{2017}

%\acmPrice{15.00}


\begin{document}
\title{Soundscape and sound space in the SoundThimble real-time gesture sonification framework}
%\titlenote{Produces the permission block, and
%  copyright information}
%\subtitle{Extended Abstract}
%\subtitlenote{The full version of the author's guide is available as
%  \texttt{acmart.pdf} document}

\author{Grigore Burloiu, Ștefan Damian,\\ Bogdan Golumbeanu}
%\authornote{Dr.~Trovato insisted his name be first.}
%\orcid{1234-5678-9012}
\affiliation{%
  \institution{CINETic UNATC}
%  \streetaddress{P.O. Box 1212}
  \city{Bucharest} 
  \state{Romania} 
%  \postcode{43017-6221}
}
\email{gburloiu@gmail.com}

\author{Valentin Mihai}
\affiliation{%
  \institution{University "Politehnica" Bucharest\\
  	Faculty of Electronics, Telecommunications and IT}
%  \streetaddress{P.O. Box 1212}
  \city{Bucharest} 
  \state{Romania} 
}
%\email{webmaster@marysville-ohio.com}


\begin{abstract}
We introduce \textit{SoundThimble}, a platform for sonic\linebreak interaction based on the relationship between human\linebreak motion and virtual objects in 3D space.

A Vicon motion capture system and custom software are used to track, interpret and sonify the movement and\linebreak gestures of a performer.

We identify three possible interaction dynamics, centred around object searching, manipulation and arrangement. We illustrate the resulting possibilities for layered structures and extended perception and expression.

The software developed is open source and portable to similar hardware systems, leaving room for further extension of the interaction mechanics.
\end{abstract}

%
% The code below should be generated by the tool at
% http://dl.acm.org/ccs.cfm
% Please copy and paste the code instead of the example below. 
%
\begin{CCSXML}
 <ccs2012>
 <concept>
 <concept_id>10010405.10010469.10010475</concept_id>
 <concept_desc>Applied computing~Sound and music computing</concept_desc>
 <concept_significance>500</concept_significance>
 </concept>
 <concept>
 <concept_id>10003120.10003121.10003128.10010869</concept_id>
 <concept_desc>Human-centered computing~Auditory feedback</concept_desc>
 <concept_significance>300</concept_significance>
 </concept>
 <concept>
 <concept_id>10003120.10003121.10003128.10011755</concept_id>
 <concept_desc>Human-centered computing~Gestural input</concept_desc>
 <concept_significance>300</concept_significance>
 </concept>
 <concept>
 <concept_id>10010147.10010178.10010224.10010226.10010238</concept_id>
 <concept_desc>Computing methodologies~Motion capture</concept_desc>
 <concept_significance>300</concept_significance>
 </concept>
 </ccs2012>
\end{CCSXML}

 \ccsdesc[500]{Applied computing~Sound and music computing}
 \ccsdesc[500]{Computing methodologies~Motion capture}
 \ccsdesc[300]{Human-centered computing~Gestural input}
 \ccsdesc[300]{Human-centered computing~Auditory feedback}

% We no longer use \terms command
%\terms{Theory}

\keywords{Sonification, motion capture, gesture spotting, interactive installation, synthesis}


\maketitle

\input{amostly}

\bibliographystyle{ACM-Reference-Format}
\bibliography{sonif-ref} 

\end{document}
